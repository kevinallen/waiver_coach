{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nfldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from ml.feature_extraction.nfldb_feature_extraction import ExtractColumns\n",
    "from ml.feature_extraction.nfldb_feature_extraction import load_feature_set\n",
    "from ml.feature_extraction.nfldb_feature_extraction import prediction_feature_set\n",
    "\n",
    "from ml.helpers.scoring_helpers import make_scorer\n",
    "from ml.helpers.scoring_helpers import score_stats\n",
    "from ml.helpers.testing_helpers import train_test_split_index\n",
    "from ml.helpers.testing_helpers import split_by_year_week\n",
    "from ml.helpers.nfldb_helpers import player_team_info\n",
    "from ml.helpers.nfldb_helpers import player_game_info\n",
    "from ml.mongo_helpers.web_helpers import VegasData\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext ml.helpers.nfldb_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(model, X_train, y_train, X_test = None, y_test = None, predict_proba = False):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    return_obj = (model,)\n",
    "    if X_test is not None:\n",
    "        if predict_proba:\n",
    "            pred_test = model.predict_proba(X_test)[:,1]\n",
    "        else:\n",
    "            pred_test = model.predict(X_test)\n",
    "\n",
    "        return_obj += (pred_test,)\n",
    "\n",
    "        if y_test is not None:\n",
    "            rmse = mean_squared_error(y_test, pred_test)**0.5\n",
    "            mae = mean_absolute_error(y_test, pred_test)\n",
    "\n",
    "            return_obj += ({'rmse':rmse, 'mae':mae},)\n",
    "\n",
    "    return(return_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vegas_dataframe(X, y, row_info, model, db, y_col):\n",
    "    # get vegas data\n",
    "    client = MongoClient()\n",
    "    mdb = client.data\n",
    "    vegas = VegasData(mdb)\n",
    "    vegas_pipe = Pipeline(steps=[('vegas', vegas)])\n",
    "    vegas_data = vegas_pipe.fit_transform(X=None)\n",
    "\n",
    "    # create a new training set with predicted values and vegas data\n",
    "    cols = ['full_name','player_id','week','year']\n",
    "    X_with_info = row_info[cols]\n",
    "\n",
    "    # get model output\n",
    "    #lr = LinearRegression()\n",
    "    #predicted = cross_val_predict(lr, X, y)\n",
    "    predicted = model.predict(X)\n",
    "    X_with_info.loc[:,y_col] = predicted\n",
    "\n",
    "\n",
    "    #team_info = player_team_info(db)\n",
    "    team_info = player_game_info(db, X_with_info['player_id'].unique(), use_current_team=False)\n",
    "    #with_team = pd.merge(X_with_info, team_info, how='inner', on=['player_id','year','week'])\n",
    "    with_team = pd.merge(X_with_info, team_info, how='left', on=['player_id','year','week'])\n",
    "    with_vegas = pd.merge(with_team, vegas_data, how='left',\n",
    "        left_on=['team','week','year'],\n",
    "        right_on=['Favorite_Abbr','Week','Year'])\n",
    "    X_vegas = pd.merge(with_vegas, vegas_data, how='left',\n",
    "        left_on=['team','week','year'],\n",
    "        right_on=['Underdog_Abbr','Week','Year'])\n",
    "\n",
    "    # TODO: dummy code weekday, month\n",
    "    # TODO: discuss whether looking at home team here makes sense\n",
    "\n",
    "    # combine columns with NaN values, caused by left joins above\n",
    "    cols_to_fill = ['Favorite_Abbr','Underdog_Abbr','Spread','Total', 'full_name']\n",
    "    for col in cols_to_fill:\n",
    "        X_vegas.loc[:,col] = X_vegas[col+'_x'].fillna(X_vegas[col+'_y'])\n",
    "\n",
    "    # determine if player's team is favored\n",
    "    X_vegas.loc[:,'is_favorite'] = X_vegas['team'] == X_vegas['Favorite_Abbr']\n",
    "    # want look at interaction of spread and favorite because\n",
    "    # otherwise spread is ambiguous, mapping False to -1 so sign of spread\n",
    "    # is reversed\n",
    "    X_vegas.loc[:,'is_favorite'] = X_vegas['is_favorite'].map({True:1, False:-1})\n",
    "    X_vegas.loc[:,'spread_x_favorite'] = X_vegas['is_favorite']*X_vegas['Spread']\n",
    "\n",
    "    # get rid of unnecessary columns\n",
    "    cols_to_keep = ['full_name','player_id','week','year','team','Total',\n",
    "        'is_favorite','spread_x_favorite', y_col]\n",
    "    cols_to_drop = [col for col in X_vegas.columns if col not in cols_to_keep]\n",
    "    cols_to_drop.extend(['Favorite_Abbr','Underdog_Abbr','Spread'])\n",
    "    X_vegas.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    X_vegas['team_points'] = (X_vegas['Total'] - X_vegas['spread_x_favorite'])/2\n",
    "\n",
    "    return X_vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = nfldb.connect()\n",
    "result_path='../results'\n",
    "full_train, pipe, stats = load_feature_set(db)\n",
    "\n",
    "# picks columns to model\n",
    "lag_cols = [stat + '_lag' for stat in stats]\n",
    "mean_cols = [stat + '_mean' for stat in stats]\n",
    "other_cols = ['same_year_lag', 'played_lag']\n",
    "\n",
    "infoColumns = ExtractColumns(like=[], exact=['year','week','time','player_id','full_name'])\n",
    "row_info = infoColumns.fit_transform(X=full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_data, predict_i, pred_info, pred_yr_wk = prediction_feature_set(db, pipe, infoColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = full_train\n",
    "pred_all = pred_data.iloc[predict_i]\n",
    "pred_results = pred_info.iloc[predict_i]\n",
    "\n",
    "# which rows did players play\n",
    "played_bool = full_train['played'] == 1\n",
    "played_index = [i for i in range(X_all.shape[0]) if played_bool[i]]\n",
    "\n",
    "# random split train and test\n",
    "train_index, test_index = train_test_split_index(X_all.shape[0], test_size=0.1, seed=0)\n",
    "\n",
    "feature_cols = lag_cols + mean_cols + other_cols\n",
    "XColumns = ExtractColumns(like=feature_cols)\n",
    "X = XColumns.fit_transform(X=X_all)\n",
    "X_pred = XColumns.fit_transform(X=pred_all)\n",
    "\n",
    "played_only = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting played\n",
      "Gradient Boosting: RMSE 0.35 | MAE 0.27\n",
      "Random Forest: RMSE 0.38 | MAE 0.27\n",
      "Logistic Regression: RMSE 0.37 | MAE 0.28\n",
      "--------------------------------------------------\n",
      "Adjusted Prediction: receiving_rec\n",
      "Predicting receiving_rec\n",
      "[ 0.01621256]\n",
      "Gradient Boosting: RMSE 1.87 | MAE 1.34\n",
      "Random Forest: RMSE 1.87 | MAE 1.34\n",
      "Linear Regression: RMSE 1.86 | MAE 1.33\n",
      "Predicting receiving_rec\n",
      "Gradient Boosting: RMSE 1.87 | MAE 1.34\n",
      "Random Forest: RMSE 2.00 | MAE 1.43\n",
      "Linear Regression: RMSE 1.86 | MAE 1.33\n",
      "--------------------------------------------------\n",
      "Adjusted Prediction: receiving_tds\n",
      "Predicting receiving_tds"
     ]
    }
   ],
   "source": [
    "#y_cols = ['rushing_yds']\n",
    "vegas_adjustment = True\n",
    "y_cols = ['played', 'receiving_rec', 'receiving_tds', 'receiving_yds', 'rushing_att', 'rushing_tds','rushing_yds']\n",
    "\n",
    "for y_col in y_cols:\n",
    "    \n",
    "    y = X_all[y_col]\n",
    "\n",
    "    if(played_only and y_col != 'played'):\n",
    "        train_i = list(set.intersection(set(train_index), set(played_index)))\n",
    "        test_i = list(set.intersection(set(test_index), set(played_index)))\n",
    "    else:\n",
    "        train_i = train_index\n",
    "        test_i = test_index\n",
    "\n",
    "    X_train = X.iloc[train_i]\n",
    "    y_train = y.iloc[train_i]\n",
    "    X_test = X.iloc[test_i]\n",
    "    y_test = y.iloc[test_i]\n",
    "    \n",
    "    # get player info for train and test data\n",
    "    X_train_info = row_info.iloc[train_i]\n",
    "    X_test_info = row_info.iloc[test_i]\n",
    "\n",
    "    ### Test Predictions\n",
    "    \n",
    "    predict_proba = y_col == 'played'\n",
    "    \n",
    "    if(predict_proba):\n",
    "        models = {\n",
    "            'gb':GradientBoostingClassifier(n_estimators=100, learning_rate=0.1),\n",
    "            'rf':RandomForestClassifier(),\n",
    "            'lin':LogisticRegression()\n",
    "        }\n",
    "    else:\n",
    "        models = {\n",
    "            'gb':GradientBoostingRegressor(n_estimators=100, learning_rate=.1),\n",
    "            'rf':RandomForestRegressor(),\n",
    "            'lin':LinearRegression()\n",
    "        }\n",
    "        \n",
    "    gb, gb_test, gb_scores = fit_predict(\n",
    "        model=models['gb'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        predict_proba=predict_proba)\n",
    "    \n",
    "    rf, rf_test, rf_scores = fit_predict(\n",
    "        model=models['rf'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        predict_proba=predict_proba)\n",
    "    \n",
    "    lin, lin_test, lin_scores = fit_predict(\n",
    "        model=models['lin'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        predict_proba=predict_proba)\n",
    "    \n",
    "    if vegas_adjustment and y_col != 'played':\n",
    "            print '-'*50\n",
    "            print 'Adjusted Prediction:', y_col\n",
    "\n",
    "            X_train_all = build_vegas_dataframe(X=X_train, y=y_train,\n",
    "                row_info=X_train_info, model=gb, db=db, y_col=y_col)\n",
    "            X_test_all = build_vegas_dataframe(X=X_test, y=y_test,\n",
    "                row_info=X_test_info, model=gb, db=db, y_col=y_col)\n",
    "\n",
    "            #features = [y_col, 'Total','is_favorite','spread_x_favorite']\n",
    "            #features = [y_col, 'team_points']\n",
    "            features = ['team_points']\n",
    "            X_cols = ExtractColumns(exact=features)\n",
    "            X_train_vegas = X_cols.fit_transform(X=X_train_all)\n",
    "            X_test_vegas = X_cols.fit_transform(X=X_test_all)\n",
    "            \n",
    "            #y_train_vegas = y_train\n",
    "            y_train_vegas = y_train - X_train_all[y_col].values\n",
    "            #y_test_vegas = y_test\n",
    "            y_test_vegas = y_test - X_test_all[y_col].values\n",
    "\n",
    "            gb_a, gb_test_a, gb_scores_a = fit_predict(\n",
    "                model=models['gb'],\n",
    "                X_train=X_train_vegas,\n",
    "                y_train=y_train_vegas,\n",
    "                X_test=X_test_vegas,\n",
    "                y_test=y_test_vegas)\n",
    "\n",
    "            rf_a, rf_test_a, rf_scores_a = fit_predict(\n",
    "                model=models['rf'],\n",
    "                X_train=X_train_vegas,\n",
    "                y_train=y_train_vegas,\n",
    "                X_test=X_test_vegas,\n",
    "                y_test=y_test_vegas)\n",
    "\n",
    "            lin_a, lin_test_a, lin_scores_a = fit_predict(\n",
    "                model=models['lin'],\n",
    "                X_train=X_train_vegas,\n",
    "                y_train=y_train_vegas,\n",
    "                X_test=X_test_vegas,\n",
    "                y_test=y_test_vegas)\n",
    "\n",
    "            print 'Predicting %s' % (y_col)\n",
    "            print lin_a.coef_\n",
    "            print 'Gradient Boosting: RMSE %.2f | MAE %.2f' % (gb_scores_a['rmse'], gb_scores_a['mae'])\n",
    "            print 'Random Forest: RMSE %.2f | MAE %.2f' % (rf_scores_a['rmse'], rf_scores_a['mae'])\n",
    "            print '%s Regression: RMSE %.2f | MAE %.2f' % ('Linear', lin_scores_a['rmse'], lin_scores_a['mae'])\n",
    "\n",
    "    # Print Results\n",
    "    print 'Predicting %s' % (y_col)\n",
    "    print 'Gradient Boosting: RMSE %.2f | MAE %.2f' % (gb_scores['rmse'], gb_scores['mae'])\n",
    "    print 'Random Forest: RMSE %.2f | MAE %.2f' % (rf_scores['rmse'], rf_scores['mae'])\n",
    "    print '%s Regression: RMSE %.2f | MAE %.2f' % ('Logistic' if predict_proba else 'Linear', lin_scores['rmse'], lin_scores['mae'])\n",
    "    # Build full models on all data\n",
    "\n",
    "    gb = gb.fit(X, y)\n",
    "    rf = rf.fit(X, y)\n",
    "    lin = lin.fit(X, y)\n",
    "    #### Next week's predictions\n",
    "    # Make prediction, just gbr for now\n",
    "    \n",
    "    if(y_col == 'played'):\n",
    "        preds = gb.predict_proba(X_pred)[:,1]\n",
    "    else:\n",
    "        preds = gb.predict(X_pred)\n",
    "\n",
    "    pred_results.loc[:,y_col] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class PredictionFeature(TransformerMixin):\n",
    "    def __init__(self, model, predict_proba=False):\n",
    "        self.model = model\n",
    "        self.predict_proba = predict_proba\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if(self.predict_proba):\n",
    "            pred = self.model.predict_proba(X)\n",
    "        else:\n",
    "            pred = self.model.predict(X)\n",
    "        return np.expand_dims(pred, 1)\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "models['en'] = Pipeline([\n",
    "        ('models', FeatureUnion([\n",
    "                        ('gb',PredictionFeature(copy.deepcopy(models['gb']), predict_proba=predict_proba)),\n",
    "                        ('rf',PredictionFeature(copy.deepcopy(models['rf']), predict_proba=predict_proba)),\n",
    "                        ('lin',PredictionFeature(copy.deepcopy(models['lin']), predict_proba=predict_proba))\n",
    "                    ])),\n",
    "        ('pred', GradientBoostingRegressor(n_estimators=1000, learning_rate=0.01, loss='lad', max_depth=5, min_samples_leaf=10))\n",
    "            ])\n",
    "\n",
    "en, en_test, en_scores = fit_predict(\n",
    "        model=models['en'],\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        predict_proba=predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
