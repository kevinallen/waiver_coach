{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "### Use nearest neighbors to find predicted distributions of players\n",
    "###################\n",
    "\n",
    "##########\n",
    "### Dependencies\n",
    "\n",
    "import nfldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "from ml.feature_extraction.nfldb_feature_extraction import ExtractColumns\n",
    "from ml.feature_extraction.nfldb_feature_extraction import load_feature_set\n",
    "from ml.feature_extraction.nfldb_feature_extraction import prediction_feature_set\n",
    "\n",
    "from ml.helpers.scoring_helpers import make_scorer\n",
    "from ml.helpers.scoring_helpers import score_stats\n",
    "from ml.helpers.testing_helpers import train_test_split_index\n",
    "from ml.helpers.testing_helpers import split_by_year_week\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "### Determines the path for distribution image plots\n",
    "def plot_image_path(result_path, pred_yr_wk):\n",
    "    return(result_path+'/knn/distimages/'+str(pred_yr_wk[0])+'_'+str(pred_yr_wk[1]))\n",
    "\n",
    "############\n",
    "### Determines the path and file name for plot data\n",
    "def plot_data_path_file(result_path, pred_yr_wk):\n",
    "    return([result_path+'/knn/distdata/',str(pred_yr_wk[0])+'_'+str(pred_yr_wk[1])+'.json'])\n",
    "\n",
    "#############\n",
    "### Function for plotting KNN distributinos and saving them\n",
    "\n",
    "def plot_knn(nn_df, plot_stat, pred_yr_wk, result_path, n_bins=2, bandwidth=2.5, save_id = True, save_time = False, save_stat = True, save_image=True):\n",
    "    # the histogram of the data\n",
    "    stat_X = nn_df.iloc[1:][plot_stat]\n",
    "    player_name = nn_df.iloc[0]['full_name']\n",
    "    player_id =  nn_df.iloc[0]['player_id']\n",
    "    n, bins, patches = plt.hist(stat_X, n_bins, normed=1, edgecolor='none', facecolor='grey', alpha=0.25)\n",
    "\n",
    "    # get plot limits\n",
    "    xmin = 0\n",
    "    xmax = max(bins)*1.1\n",
    "    ymin = 0\n",
    "    ymax = max(n)*1.1\n",
    "\n",
    "    # get bins for kernel density plot\n",
    "    smooth_bins = np.linspace(xmin, xmax, 100)\n",
    "\n",
    "    # set up kernel density\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(X=stat_X[:,np.newaxis])\n",
    "    y_smooth = np.exp(kde.score_samples(smooth_bins[:,np.newaxis]))\n",
    "    y_smooth\n",
    "\n",
    "    l = plt.plot(smooth_bins, y_smooth, 'b--', linewidth=1)\n",
    "    plt.xlabel(plot_stat)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.title(player_name)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save_image:\n",
    "        if not os.path.exists(result_path):\n",
    "            os.makedirs(result_path)\n",
    "\n",
    "        save_path = result_path + '/'\n",
    "        fname_list = []\n",
    "        if save_id:\n",
    "            fname_list += [player_id]\n",
    "        else:\n",
    "            fname_list += [player_name]\n",
    "\n",
    "        if save_time:\n",
    "            fname_list += [str(pred_yr_wk[0]), str(pred_yr_wk[1])]\n",
    "\n",
    "        if save_stat:\n",
    "            fname_list += [plot_stat]\n",
    "\n",
    "        save_path += '_'.join(fname_list) + '.png'\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    \n",
    "    return({player_id:{'raw':{'x':list(bins), 'y':list(n)}, 'smooth':{'x':list(smooth_bins), 'y':list(y_smooth)}}})\n",
    "\n",
    "############\n",
    "### Function for saveing plot data as json to support web viz\n",
    "def save_plot_data_json(nn_dict, result_path, pred_yr_wk):\n",
    "    json_fp = plot_data_path_file(result_path, pred_yr_wk)\n",
    "\n",
    "    if not os.path.exists(json_fp[0]):\n",
    "                os.makedirs(json_fp[0])\n",
    "\n",
    "    with open('/'.join(json_fp), 'w+') as fp:\n",
    "        json.dump(nn_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "### CONFIGURE\n",
    "pred_week = 10 #None\n",
    "db = nfldb.connect()\n",
    "result_path='../results'\n",
    "\n",
    "### LOAD DATA\n",
    "# load train data\n",
    "full_train, pipe, stats = load_feature_set(db)\n",
    "\n",
    "# picks columns to model\n",
    "lag_cols = [stat + '_lag' for stat in stats]\n",
    "mean_cols = [stat + '_mean' for stat in stats]\n",
    "other_cols = ['same_year_lag', 'played_lag']\n",
    "\n",
    "infoColumns = ExtractColumns(like=[], exact=['year','week','time','player_id','full_name'])\n",
    "row_info = infoColumns.fit_transform(X=full_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_data, predict_i, pred_info, pred_yr_wk = prediction_feature_set(db, pipe, infoColumns, pred_week=pred_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "### PREPARE DATA FOR TRAIN AND PREDICT\n",
    "# train data with all columns\n",
    "X_all = full_train\n",
    "\n",
    "# prediction data with all columns\n",
    "pred_all = pred_data.iloc[predict_i]\n",
    "\n",
    "# which rows did players play\n",
    "played_bool = full_train['played'] == 1\n",
    "played_index = [i for i in range(X_all.shape[0]) if played_bool[i]]\n",
    "\n",
    "# random split train and test\n",
    "train_index, test_index = train_test_split_index(X_all.shape[0], test_size=0.1, seed=0)\n",
    "\n",
    "feature_cols = lag_cols + mean_cols + other_cols\n",
    "XColumns = ExtractColumns(like=feature_cols)\n",
    "X = XColumns.fit_transform(X=X_all)\n",
    "X_pred = XColumns.fit_transform(X=pred_all)\n",
    "\n",
    "played_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "### SET UP & TRAIN KNN\n",
    "# fit k nearest neighbors\n",
    "k = 100\n",
    "played_only = True\n",
    "i_knn = played_index if played_only else range(X.shape[0])\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=k).fit(X.iloc[i_knn])\n",
    "\n",
    "# returns tuple of (distances, indices of neighbors)\n",
    "# for prediction set\n",
    "distance, neighbor = nn.kneighbors(X=X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "### READ AND PLOT KNN RESULTS\n",
    "nn_dict = {}\n",
    "for check_i in range(pred_all.shape[0]):\n",
    "    # check neighbors\n",
    "    # check_nn is a data frame where the first row is the player\n",
    "    # and the rest of the rows are the nearest neighbors\n",
    "    check_nn = pred_all.iloc[[check_i],:].append(X_all.iloc[i_knn].iloc[neighbor[check_i,:]])\n",
    "    check_nn['StandardPoints'] = score_stats(check_nn, make_scorer(base_type='standard'))\n",
    "    check_nn['PPRPoints'] = score_stats(check_nn, make_scorer(base_type='ppr'))\n",
    "\n",
    "    nn_i = plot_knn(check_nn, save_image=True, plot_stat='StandardPoints', pred_yr_wk=pred_yr_wk, result_path=plot_image_path(result_path, pred_yr_wk), n_bins=25, bandwidth=2.5)\n",
    "    nn_dict.update(nn_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_plot_data_json(nn_dict, result_path, pred_yr_wk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
